{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad39aa4",
   "metadata": {},
   "source": [
    "# ML | Kaggle Breast Cancer Wisconsin Diagnosis using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c74c53f",
   "metadata": {},
   "source": [
    "### Logistic Regression is used to predict whether the given patient is having Malignant or Benign tumor based on the attributes in the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a51fc004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# laoding libraries\n",
    "\n",
    "# performing linear algebra\n",
    "import numpy as np\n",
    "\n",
    "#data processing\n",
    "import pandas as pd\n",
    "\n",
    "#visualization\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cd662be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\ASUS\\\\Desktop\\\\machine  and deep learning projects\\\\BreastCancer\\\\data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74d2b346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84458202</td>\n",
       "      <td>M</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>844981</td>\n",
       "      <td>M</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84501001</td>\n",
       "      <td>M</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>...</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "5    843786         M        12.45         15.70           82.57      477.1   \n",
       "6    844359         M        18.25         19.98          119.60     1040.0   \n",
       "7  84458202         M        13.71         20.83           90.20      577.9   \n",
       "8    844981         M        13.00         21.82           87.50      519.8   \n",
       "9  84501001         M        12.46         24.04           83.97      475.9   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760         0.30010              0.14710   \n",
       "1          0.08474           0.07864         0.08690              0.07017   \n",
       "2          0.10960           0.15990         0.19740              0.12790   \n",
       "3          0.14250           0.28390         0.24140              0.10520   \n",
       "4          0.10030           0.13280         0.19800              0.10430   \n",
       "5          0.12780           0.17000         0.15780              0.08089   \n",
       "6          0.09463           0.10900         0.11270              0.07400   \n",
       "7          0.11890           0.16450         0.09366              0.05985   \n",
       "8          0.12730           0.19320         0.18590              0.09353   \n",
       "9          0.11860           0.23960         0.22730              0.08543   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "5  ...          23.75           103.40       741.6            0.1791   \n",
       "6  ...          27.66           153.20      1606.0            0.1442   \n",
       "7  ...          28.14           110.60       897.0            0.1654   \n",
       "8  ...          30.73           106.20       739.3            0.1703   \n",
       "9  ...          40.68            97.65       711.4            0.1853   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "5             0.5249           0.5355                0.1741          0.3985   \n",
       "6             0.2576           0.3784                0.1932          0.3063   \n",
       "7             0.3682           0.2678                0.1556          0.3196   \n",
       "8             0.5401           0.5390                0.2060          0.4378   \n",
       "9             1.0580           1.1050                0.2210          0.4366   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "5                  0.12440          NaN  \n",
       "6                  0.08368          NaN  \n",
       "7                  0.11510          NaN  \n",
       "8                  0.10720          NaN  \n",
       "9                  0.20750          NaN  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c53572c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddfa2f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are dropping columns – ‘id’ and ‘Unnamed: 32’ as they have no role in prediction\n",
    "data.drop(['Unnamed: 32', 'id'], axis = 1)\n",
    "data.diagnosis = [1 if each == \"M\" else 0 for each in data.diagnosis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea9acb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and output data\n",
    "y = data.diagnosis.values\n",
    "x_data = data.drop(['diagnosis'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23638747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalisation\n",
    "x = (x_data - np.min(x_data)) / (np.max(x_data) - np.min(x_data)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d75f682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train:  (32, 455)\n",
      "x test:  (32, 114)\n",
      "y train:  (455,)\n",
      "y test:  (114,)\n"
     ]
    }
   ],
   "source": [
    "# splitting data for training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "x_train = x_train.T\n",
    "x_test = x_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T\n",
    "\n",
    "print(\"x train: \", x_train.shape)\n",
    "print(\"x test: \", x_test.shape)\n",
    "print(\"y train: \", y_train.shape)\n",
    "print(\"y test: \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1932ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight and bias\n",
    "def initialize_weights_and_bias(dimension):\n",
    "    w = np.full((dimension, 1), 0.01)\n",
    "    b = 0.0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b73dc8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid Function – calculating z value\n",
    "def sigmoid(z):\n",
    "    y_head = 1 / (1 + np.exp(-z))\n",
    "    return y_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bd4b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward-Backward Propogation\n",
    "def forward_backward_propagation(w, b, x_train, y_train):\n",
    "    z = np.dot(w.T, x_train) + b\n",
    "    y_head = sigmoid(z)\n",
    "    loss = - y_train * np.log(y_head) - (1 - y_train) * np.log(1 - y_head)\n",
    "    # x_train.shape[1]  is for scaling\n",
    "    cost = (np.sum(loss)) / x_train.shape[1]\n",
    "    \n",
    "    # backward propagation\n",
    "    derivative_weight = (np.dot(x_train, ((y_head - y_train).T))) / x_train.shape[1]\n",
    "    derivative_bias = np.sum(y_head - y_train) / x_train.shape[1]\n",
    "    gradients = {\"derivative_weight\": derivative_weight, \"derivative_bias\": derivative_bias}\n",
    "    return cost, gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89447353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating Parameters\n",
    "def update(w, b, x_train, y_train, learning_rate, number_of_iteration):\n",
    "    cost_list = []\n",
    "    cost_list2 =  []\n",
    "    index = []\n",
    "    \n",
    "     # updating(learning) parameters is number_of_iterarion times\n",
    "    for i in range(number_of_iteration):\n",
    "        # make forward and backward propagation and find cost and gradients\n",
    "        cost, gradients = forward_backward_propagation(w, b, x_train, y_train)\n",
    "        cost_list.append(cost)\n",
    "        \n",
    "        #lets update\n",
    "        w = w - learning_rate * gradients[\"derivative_weight\"]\n",
    "        b = b - learning_rate * gradients[\"derivative_bias\"]\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            cost_list2.append(cost)\n",
    "            index.append(i)\n",
    "            print(\" Cost after iteration % i: % f\" %(i, cost))\n",
    "    \n",
    "    # update(learn) parameters weights and bias\n",
    "    parameters = {\"weight\": w, \"bias\": b}\n",
    "    plt.plot(index, cost_list2)\n",
    "    plt.xticks(index, rotation = 'vertical')\n",
    "    plt.xlabel(\"Number of iteration\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    return parameters, gradients, cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "025b3fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "def predict(w, b, x_test):\n",
    "    # x_test is a input for forward propagation\n",
    "    z = sigmoid(np.dot(w.T, x_test) + b)\n",
    "    Y_prediction = np.zeros((1, x_test.shape[1]))\n",
    "    # if z is bigger than 0.5, our prediction is sign one (y_head = 1),\n",
    "    # if z is smaller than 0.5, our prediction is sign zero (y_head = 0),\n",
    "    for i in range(z.shape[1]):\n",
    "        if z[0, i] <= 0.5:\n",
    "            Y_prediction[0, i] = 0\n",
    "        else:\n",
    "            Y_prediction[0, i] = 1\n",
    "    return Y_prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "839afc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "def logistic_regression(x_train, y_train, x_test, y_test, learning_rate, num_iterations):\n",
    "    \n",
    "    dimension = x_train.shape[0]\n",
    "    w, b = initialize_weights_and_bias(dimension)\n",
    "    \n",
    "    parameters, gradients, cost_list = update(w, b, x_train, y_train, learning_rate, num_iterations)\n",
    "    \n",
    "    y_prediction_test = predict(parameters[\"weight\"], parameters[\"bias\"], x_test)\n",
    "    y_prediction_train = predict(parameters[\"weight\"], parameters[\"bias\"], x_train)\n",
    "    \n",
    "    # train/test errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2e1d08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cost after iteration  0:  nan\n",
      " Cost after iteration  10:  nan\n",
      " Cost after iteration  20:  nan\n",
      " Cost after iteration  30:  nan\n",
      " Cost after iteration  40:  nan\n",
      " Cost after iteration  50:  nan\n",
      " Cost after iteration  60:  nan\n",
      " Cost after iteration  70:  nan\n",
      " Cost after iteration  80:  nan\n",
      " Cost after iteration  90:  nan\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 37.142857142857146 %\n",
      "test accuracy: 37.71929824561403 %\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(x_train, y_train, x_test, y_test, learning_rate = 1, num_iterations = 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db31539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
